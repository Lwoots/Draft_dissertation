# Methods section

## Field sampling



Field sampling was conducted between August 2019 and January 2020. For taxa in the Ramosa and Setacea groups, the number of sampled localities per taxon varied between two, for the range restricted _E. setacea_ subsp. _disticha_ and _E. setacea_ subsp. _uniflora_, and twelve for the widespread _E. ramosa_ subsp. _ramosa_. For these taxa, between four and six individuals were sampled from each locality, and as far as possible the sampled individuals were situated >30 m apart. For taxa included in the remaining species groups, the number of sampled localities varied between one and two, with a single individual being sampled from each locality. For each accession sampled, young leaf and culm tissue sampled was collected and dried in silica, before being stored in an airtight container at -20°C to prevent DNA degradation. In addition, a flowering specimen of each accession was pressed as a voucher, to be deposited at the Bolus Herbarium at the University of Cape Town. The outgroup _Microlaena stipoides_ accession was sampled from the living collection of the Royal Botanic Gardens, Kew. OTHER OUTGROUP



## DNA extraction

DNA extraction was carried out at the Systematics Laboratory at the Department of Biological Sciences, University of Cape Town. For each sample, 100 mg of frozen, silica-dried leaf and culm tissue was finely ground in liquid nitrogen using a mortar and pestle. Small amounts of sterilised silica and polyvinyl pyrrolidone was added to each sample before grinding, to increase friction and decrease polysaccharide extraction respectively. DNA samples were then extracted in 1.5 ml Eppendorf tubes using the cetyl-trimethylammonium bromide (CTAB) method (@Doyle1987) with three ethanol (70%) washes. The resulting extracts were treated with RNAse A (Omega Bio-tek, Norcross, GA, USA), and purified using AMPure XP paramagnetic beads (Beckman Coulter, High Wycombe, UK) following the manufacturers instructions. The concentration and purity of each extract was checked using a NanoDrop ND-1000 spectrophotometer (ThermoFisher Scientific, Waltham, MA, USA). Samples with concentrations ≥50 ng $\mu$l^-1^ and 260/280 nm absorbance ratios between 1.7 and 2 considered suitable for genotyping-by-sequencing (GBS), while those with concentrations ≥25 ng $\mu$l^-1^ considered suitable targeted enrichment sequencing. 

## Targeted enrichment sequencing

Targeted enrichment sequencing was conducted in order to infer a multilocus phylogenetic hypothesis for the Cape _Ehrharta_ (@Lemmon2012). In general, each sampled population was represented by a single accession, with few exceptions where two accessions were sequenced to ratify quality between sequencing runs. Library preparation and hybridisation for targeted enrichment sequencing was carried out at the Sackler Phylogenomic Laboratory, within the Jodrell Laboratory at Royal Botanic Gardens, Kew (Richmond, Surrey, UK). The DNA concentration present in the extracts was measured with a QuantusTM fluorometer (Promega corporation, Madison USA) using the using QuantiFluorR dsDNA System kit (Promega corporation, Madison USA). The samples were diluted to 200 ng DNA in 26 $\mu$l with Milli-Q water. The DNA was then sheared to fragments with an average of length of 350 bp by sonication for 75 s with a Covaris Focused-ultrasonicator M220 (Woburn, Massachusetts 01801 www.covarisinc.com)

Library preparation was performed using NEBNext Ultra II DNA Library Prep Kit for Illumina (New England Biolabs), using half the recommended volumes to maximise use of reagents and indices. AMPure paramagnetic beads (Beckman Coulter, High Wycombe, UK) were used for size selection of DNA fragments. Libraries were indexed with the NEBNext Multiplex Oligos for Illumina (Dual Index Primer Set 1, New England Biolabs), and enriched with the following thermocycler conditions: initial denaturation for 30s at 98$^\circ$C, seven cycles comprising denaturation for 10 s at 98$^\circ$C and annealing and extension for 75 s at 65$^\circ$C, followed by a final extension for 5 mins at 65$^\circ$C. The resulting enriched libraries were cleaned with AMPure paramagnetic beads (Beckman Coulter, High Wycombe, UK), and the quality of the libraries were checked using Agilent Technologies 4200 Tapestation (Agilent Technologies, Palo Alto, California, USA). A library was considered good quality if it had a concentration of greater than 4 ng $\mu$l^-1^ and average fragment size of 450 bp to 500 bp. If a library failed the quality check, it was either re-amplified, underwent size selection again, or was entirely repeated. 


Libraries were normalised to a concentration of 10 nM, and 10 $\mu$l per sample was pooled into batches of 12 or 24 samples per reaction. The pools were vacuum dried using a miVac Duo Concentrator (Genevac, UK) and subsequently eluted in 8 $\mu$l of 10 mM tris buffer. The pools were enriched using the Angiosperms-353 v 1 target capture kit (@Johnson2019) following the manufacturers instructions (Arbor Biosciences, Ann Arbor, Michigan, USA). Hybridisation took place for 16 hrs at 65$^\circ$C, and the resulting product was amplified with 12 cycles of PCR. The reaction quality was checked using an Agilent Technologies 4200 Tapestation (Agilent Technologies, Palo Alto, California, USA). Reactions were normalised to 4mM and pooled. Sequencing took place either on a Illumina® HiSeq at Macrogen (Seoul, South Korea) or on an Illumina® MiSeq at Royal Botanic Gardens, Kew, producing 2 x 150 bp reads.

 

## Read trimming, filtering and assembly

The raw reads were cleaned using Trimmomatic v.0.39 (@Bolger2014). Illuminaclip palindrome mode, with the reference file TruSeq3-PE.fa, was used to remove Illumina sequencing adaptors. Palindrome mode had the following settings: SeedMismatches = 1, palindromeClipThreshold = 30, simpleClipThreshold = 6, minAdapterLength  =  2; keepBothReads = T RUE. Poor quality reads were then trimmed with the Maxinfo option. Maxinfo balances the utility of retaining reads of an informative length against the costs of retaining incorrect bases. Initially, Maxinfo is lenient towards potential error calls at a shorter read length, becoming stricter as read length increases. The settings used were targetLength = 40 and strictness = 85. Finally, reads of <36 bp were removed using MinLength. Overall read quality and adaptor content of the remaining reads were checked using FastQC v.0.11.8 (@Andrews2010)



**Read assembly**

Reads were assembled using the pipeline HybPiper v.1.3.1 (@Johnson2016).  HybPiper consists of a series of python scripts that use SPAdes (@Bankevich2012) and other bioinfomatic tools to assemble reads to a target file. The pipeline first sorts and groups together individual reads for a gene by mapping each read to the gene sequence in the target file.  Once the reads are sorted by gene, they are de novo assembled using SPAdes, and then realigned to the reference sequence. If multiple contigs are assembled per gene, the contig with either the greatest depth or greatest similarity to the reference file is chosen for the consensus sequence. HybPiper gives the option of two different mapping algorithms, BLASTX (@Altschul1990) and BWA (@Durbin2009). I ran the pipeline using BLASTX, as it is a less strict algorithm than BWA, and so maximises the number of reads mapped and the lengths of the final sequences. A coverage of four reads was considered sufficient to generate a consensus sequence. Reads were mapped to a multi-species, amino acid target file matching the probes from the Angiosperms-353 baitset (@Johnson2019). In the case of a multi-species target file, such as the one used here, HybPiper can determine which target sequence for a gene is the most suitable given the sample. The Hybpiper pipeline was also used to assemble the cleaned reads of a full genome of a _Oryza sativa_ Japonica cultivar downloaded from Genbank (https://www.ncbi.nlm.nih.gov/sra/SRR10389404).



**Identification of paralogs, gene choice**

Paralogs are genes related by an ancestral duplication event, rather than by sharing a common origin as is the case with orthologous genes (Koonin 2005, Schrempf2020). A key assumption of phylogenetics is that the genes used within an analysis are orthologous. Fortunately, HypPiper is able to identify potential paralogs. If HybPiper 1.3.1 recovers two or more similar contigs that cover at least 85% of the coding region's reference sequence, it flags the region as containing potential paralogs. Note that two similar length contigs for a gene may also indicate the presence of an allele. The two can be differentiated by constructing a gene tree. A gene is paralogous if the main contigs cluster separately within the gene tree to the alternative contigs, as this indicates a gene duplication event. Alternatively, the main and secondary contigs grouping as sisters within a gene would suggest alleles.

In this analysis, HybPiper flagged 50 genes with paralog warnings. Within each gene, the number of samples flagged with paralogs varied between 1 and 39 samples. I disregarded genes with less than 2 flagged samples, as these were more likely to be alleles rather than paralogs. This left 18 genes that contained potential paralogs. HybPiper contains a script, paralog_retriever.py that will extract both the main and secondary contigs for a gene into a fasta file. Each resulting fasta was then aligned with MAFFT, followed by genetree construction using IQtree 1.6.11.  The trees were inspected in Geneious. While it wasn't always clear cut whether the tree exhibited paralogs or not, I errored on the side of caution and removed any gene that wasn't obviously allelic. Therefore a total of 11 genes were deemed paralogs, and were removed from the dataset.

Two sets of loci were chosen for further phylogenetic analysis. One, refered to as the full coverage dataset, retained genes that were present in all 109 samples, outgroups and rice included. This resulted in a total of 235 genes. The other, referred to as the ninety percent coverage dataset, retained genes that were present in at least 90% of all samples. This cut off was chosen as a compromise between missing data, and using as many genes as possible. These dataset divisions were used for exons, supercontigs, and introns, giving six datasets in total. Individual genes were aligned using MAFFT 7.427 with the settings --localpair --maxiterate 1000. The resulting alignments were then trimmed of gappy and poorly aligned regions with TrimAL 1.2. Alignment statistics were calculated by AMAS (Borowiec, 2016).



**Maximum likelihood trees** 

The alignments were concatenated using AMAS (Borowiec, 2016), which also generates a partition file delimiting where each loci starts in the concatenated alignment. Most loci have a unique evolutionary history, and are able to evolve independently of the rest of the genome. Each region is therefore expected to have a different rate and pattern of evolution. Therefore each locus should be fitted with a model of evolution that best fits its history. To reduce parameter space, it is also best to partition together loci with similar models of evolution. IQtree is able to fit models of evolution to each loci, and can implement Lanfear's partitionfinder2 (Chernomor 2016, Lanfear). Due to the high computational burden, I choose to use the relaxed hierarchical clustering algorithm (-rcluster) (Lanfear2014), which only examines the top n% partition merging schemes. The exon supermatrices were partitioned using -rcluster 10, while the intron and supercontig supermatrices were run with -rcluster 2 due to computational time limits. The locus limits were used as the initial partitions.

I then reconstructed ML trees on the merged partition datasets using IQtree v. To estimate node support, I used 1000 ultrafast bootstraps (UFBoot, Hoang 2017). A node is considered to have good support if it has greater than 95% UFBoot value.



**Multi-species coalescent trees**

The evolutionary history of a gene often differs from the history of a species due to incomplete lineage sorting (ILS), horizontal gene transfer and hybridisation resulting in gene trees that differ from the true species tree. Concatenated ML methods are unlikely to capture these patterns. Conversely, the multi-species coalescent model allows the history genes to be modeled separately from the species history, therefore allowing for processes such as ILS to occur. Summary-based methods of species tree estimation such as ASTRAL are consistent with multi-species coalescent theory, and are therefore thought to be more accurate than ML for large datasets. Astral estimates the species tree that has the most quartets that are shared with the gene trees. Individual gene trees were constructed from the loci alignments using IQTree with the default settings. ASTRAL-III v5.6.3 was used to infer the species tree from the individual gene trees. As coalescent-based methods are less sensitive to missing taxa (Hosner 2016, Sayyari 2017, Molloy2018), I used only the ninety-percent coverage datasets for this analysis.



## GBS

Four DNA extracts per population were sent to Novogene Genome Sequencing Company Ltd. in Beijing, China for library preparation and sequencing following Novogene's protocols. In brief, each DNA sample was digested with restriction enzymes, and the resulting fragments were ligated to barcoded adaptors. The samples are then PCR amplified, pooled and size-selected. A Qubit® 2.0 fluorometer and a Agilent® 2100 bioanalyzer were used to check the concentration and insert sizes of the completed libraries. The samples were sequenced using paired-end sequencing on a Illumina platform, with a read length of 144 bp. The raw data was then filtered by Novogene to remove paired reads where either read is adaptor contaminated, has ambiguous nucleotides accounting for > 10 % of the read, or where more than 50% of either read consists of poor quality nucleotides.

The dDocent pipeline (ref) was used to map and call SNPs. The pipeline was run separately on each of the Rehmannii, Ramosa and Rupestris clades. First, the reads were trimmed using Trimmomatic to remove any remaining reads with adaptor contamination, or with bases below a quality score of 20, or that contain a five base pair window with an average quality score of less than ten. The reads were then mapped to a reference genome (link to ncbi) using the MEM algorithm of BWA with the default settings (-A 1 -B 4 -O 6). Single nucleotide polymorphisms (SNPs) were called using using FreeBayes v1.2.0 (Garrison & Marth, 2012), which is a Bayesian-based variant detection program. The SNPs were concatenated into a variant call file (VCF) using VCFtools v3.0 (Danecek et al., 2011), and filtered using the dDocent pipeline recommendations with the following exceptions. I kept only variants that had been genotyped in at least 10% of individuals, and individuals with more than 30% missing data were removed. Loci were also filtered if they were missing in over 10% of individuals within five or more populations. A within-population Hardy-Weinberg Equilibrium filter was applied at a significance level of 0.001 to remove erroneous variant calls and reduce the dataset to only biallelic SNPs.

Individuals within each clade were then assigned to potential ancestral gene pools with a sparse non-negative matrix factorisation (sNMF) algorithm (@Frichot2014) using the R package _LEA_ (ref). The sNMF algorithm has a similar level of accuracy to likelihood-based inferences of population structure, such as STRUCTURE (ref) and ADMIXTURE (ref), but with a faster computing time (@Frichot2014). One hundred ancestry coefficient matrices (Q matrices) were generated for each value of K between K = 1 and K = 20 for the Ramosa and Rehmannii clades, and  K = 1 and K = 25 for the Rupestris clade. K represents the number of potential ancestral gene pools. The quality of the fit of each value of K given the data was evaluated using the average entropy criterion of the one hundred runs. The entropy criterion evaluates the fit of the statistical model using a cross‐validation technique, with lower values representing a better fit (@Frichot2015). However, I also used the value of K that corresponded to the number of putative species within each clade that was recovered by the phylogenetic analyses. Clumpak (cluster Markov packager across K, Kopelman et al., 2015) was used to summarise the Q matrices for the relevant K values, and the results visualised using the R package pophelper. Finally, PCOAs of the filter SNP dataset were generated using the R packages dartR and adegenet.



## Morphological measurements and analysis



Morphological traits of four flowering individuals per population in the high elevation clades were measured using either digital vernier callipers or a dissection microscope. If a given population had fewer than four flowering individuals. Only one individual per taxon for the low-elevation clades was phenotyped. Where possible, individuals were corresponding to the phylogeny tips were selected, although occasionally another individual from the same population had to be used if the original sequenced individual was not in flower.  For _E. microlaena_ a herbarium specimen (Verboom 695) from the same locality as our collection was used, as all our voucher specimens were under-developed. In total, 18 floral and vegetative traits were measured, as shown in Table. Potentially informative ratios of these traits, for example spikelet shape (spikelet width x spikelet length), were also used in downstream analyses (Table).

Results from the phylogenetic and GBS analyses were used to inform the structure of the morphological analysis. Each major high-elevation clade was analysed separately in order to examine fine-scale variation, and individuals were grouped according to potential new taxa, rather than existing taxonomy. A principal components analysis was used to visualise morphological similarities between taxa. Linear discriminant analyses to maximise the distance between groups. I also present univariate boxplots of particularly informative traits.

