---
title: "Chapt 2"
author: "Lara Wootton"
date: "13/07/2020"
output: 
  pdf_document:
      latex_engine: xelatex
bibliography: Chapt2_refs.bib
csl: harvard-university-of-cape-town.csl
---


# Methods section

## Field sampling


Field sampling was conducted between August 2019 and January 2020. For taxa in the Ramosa and Setacea groups, the number of sampled localities per taxon varied between two, for the range restricted _E. setacea_ subsp. _disticha_ and _E. setacea_ subsp. _uniflora_, and twelve for the widespread _E. ramosa_ subsp. _ramosa_. Between four and six individuals were sampled from each locality, with the sampled individuals being selected as far as possible to be >30 m apart. For taxa included in the remaining species groups, the number of sampled localities varied between one and two, with a single individual being sampled from each locality. Young leaf and culm tissue was collected from each accession, and dried in silica, before being stored in an airtight container at -20°C to prevent DNA degradation. In addition, a flowering specimen of each accession was pressed as a voucher, to be deposited at the Bolus Herbarium at the University of Cape Town. Finally, _Microlaena stipoides_ and _Tetrarrhena laevis_ were sampled from the living collection and tissue bank of the Royal Botanic Gardens, Kew, respectively.


## DNA extraction

DNA extraction was carried out at the Systematics Laboratory at the Department of Biological Sciences, University of Cape Town, with the exception of _M. stipoides_ and _T. laevis_, which were extracted at the Royal Botanic Gardens, Kew. For each sample, 100 mg of frozen, silica-dried leaf and culm tissue was finely ground in liquid nitrogen using a mortar and pestle. Sterilised silica and polyvinyl pyrrolidone was added to each sample before grinding, to increase friction and decrease polysaccharide extraction respectively. DNA samples were then extracted in 1.5 ml Eppendorf tubes using the cetyl-trimethylammonium bromide (CTAB) method [@Doyle1987] with three 70% ethanol washes. The resulting extracts were treated with RNAse A (Omega Bio-tek, Norcross, GA, USA), and purified using AMPure XP paramagnetic beads (Beckman Coulter, High Wycombe, UK) following the manufacturers' instructions. The concentration and purity of each extract was checked using a NanoDrop ND-1000 spectrophotometer (ThermoFisher Scientific, Waltham, MA, USA). Samples with concentrations ≥50 ng µl^-1^, and 260/280 nm absorbance ratios between 1.7 and 2, were considered suitable for genotyping-by-sequencing (GBS), while those with concentrations ≥25 ng µl^-1^ were considered suitable for targeted enrichment sequencing. 

## Targeted enrichment sequencing

Targeted enrichment sequencing was conducted in order to infer a multilocus phylogenetic hypothesis for the Cape _Ehrharta_ [@Lemmon2012]. In general, each sampled population was represented by a single accession, with few exceptions where two accessions from a population were sequenced to ratify quality between sequencing runs. In total, there were 106 Cape _Ehrharta_ samples, and one sample from each of _M. stipoides_ and _T. laevis_. Library preparation and hybridisation for targeted enrichment sequencing was carried out at the Sackler Phylogenomic Laboratory, within the Jodrell Laboratory at the Royal Botanic Gardens, Kew (Richmond, Surrey, UK). The DNA concentration present in the extracts was measured with a QuantusTM fluorometer (Promega corporation, Madison USA) using the using QuantiFluorR dsDNA System kit (Promega corporation, Madison USA). The samples were diluted to 200 ng DNA in 26 µl with Milli-Q water. The DNA was then sheared to fragments with an average of length of 350 bp by sonication for 75 s with a Covaris Focused-ultrasonicator M220 (Woburn, Massachusetts 01801, www.covarisinc.com)

Library preparation was performed using NEBNext Ultra II DNA Library Prep Kit for Illumina (New England Biolabs), using half the recommended volumes to maximise use of reagents and indices. AMPure paramagnetic beads (Beckman Coulter, High Wycombe, UK) were used for size selection of DNA fragments. Libraries were indexed with the NEBNext Multiplex Oligos for Illumina (Dual Index Primer Set 1, New England Biolabs), and enriched with the following thermocycler conditions: initial denaturation for 30s at 98$^\circ$C, seven cycles comprising denaturation for 10 s at 98$^\circ$C and annealing and extension for 75 s at 65$^\circ$C, followed by a final extension for 5 mins at 65$^\circ$C. The resulting enriched libraries were then cleaned with AMPure paramagnetic beads (Beckman Coulter, High Wycombe, UK), and the quality of the libraries were checked using Agilent Technologies 4200 Tapestation (Agilent Technologies, Palo Alto, California, USA). A library was considered good quality if it had a concentration of greater than 4 ng µ^-1^ and average fragment size of 450 bp to 500 bp. If a library failed the quality check, it was either re-amplified, underwent size selection again, or was entirely repeated. 


Libraries were normalised to a concentration of 10 nM, and 10 µl per sample was pooled into batches of 12 or 24 samples per reaction. The pools were vacuum dried using a miVac Duo Concentrator (Genevac, UK) and subsequently eluted in 8 µl of 10 mM tris buffer. The pools were enriched using the Angiosperms-353 v.1 target capture kit [@Johnson2019], following the manufacturers instructions (Arbor Biosciences, Ann Arbor, Michigan, USA). Hybridisation took place for 16 hrs at 65$^\circ$C, and the resulting product was amplified with 12 cycles of PCR. The reaction quality was checked using an Agilent Technologies 4200 Tapestation (Agilent Technologies, Palo Alto, California, USA). Reactions were normalised to 4mM and pooled. Sequencing took place either on a Illumina® HiSeq at Macrogen (Seoul, South Korea) or on an Illumina® MiSeq at Royal Botanic Gardens, Kew, producing 2 x 150 bp reads.

 

## Read trimming, filtering and assembly

The raw reads were cleaned using Trimmomatic v.0.39 [@Bolger2014]. Illuminaclip palindrome mode, with the reference file TruSeq3-PE.fa, was used to remove Illumina sequencing adaptors. Palindrome mode had the following settings: SeedMismatches = 1, palindromeClipThreshold = 30, simpleClipThreshold = 6, minAdapterLength = 2; keepBothReads = TRUE. Poor quality reads were then trimmed with the Maxinfo option. Maxinfo balances the utility of retaining reads of an informative length against the costs of retaining incorrect bases. Initially, Maxinfo is lenient towards potential error calls at a shorter read length, becoming stricter as read length increases. The settings used were targetLength = 40 and strictness = 85. Finally, reads of <36 bp were removed using MinLength. Overall read quality and adaptor content of the remaining reads were checked using FastQC v.0.11.8 [@Andrews2010].

Reads were assembled using the pipeline HybPiper v.1.3.1 [@Johnson2016]. HybPiper consists of a series of python scripts that use SPAdes [@Bankevich2012] and other bioinfomatic tools to assemble reads to a target file. The pipeline first sorts and groups together individual reads for a gene by mapping each read to the gene sequence in the target file. Once the reads are sorted by gene, they are _de novo_ assembled using SPAdes, and then realigned to the reference sequence. If multiple contigs are assembled per gene, the contig with either the greatest depth or greatest similarity to the reference file is chosen for the consensus sequence. HybPiper gives the option of two different mapping algorithms, BLASTX [@Altschul1990] and BWA [@Li2010]. I ran the pipeline using BLASTX, as it is a less strict algorithm than BWA, and so maximises the number of reads mapped and the lengths of the final sequences. A coverage of four reads was considered sufficient to generate a consensus sequence. Reads were mapped to a multi-species, amino acid target file matching the probes from the Angiosperms-353 baitset [@Johnson2019]. In the case of a multi-species target file, such as the one used here, HybPiper can determine which target sequence for a gene is the most suitable given the sample. The Hybpiper pipeline was also used to assemble the cleaned reads of a full genome of an _Oryza sativa_ Japonica cultivar downloaded from Genbank (SRX7089781).

HypPiper was also used to identify potential paralogs. Where HybPiper recovers two or more contigs that cover >85% of the coding region's reference sequence, it flags the region as containing potential paralogs. The presence of two contigs of similar length at a gene locus may, however, alternatively indicate the presence of multiple alleles, a situation which can be differentiated using gene tree inference. In these analyses, HybPiper flagged 50 genes with paralog warnings. Within each gene, the number of samples flagged with paralogs varied between one and 39 samples. I disregarded genes (N = 32) with two or fewer flagged samples, as these were more likely to be alleles rather than paralogs. For the remaining 18 genes, the script paralog_retriever.py was used to extract the main and secondary contigs for a gene into a fasta file, which was then aligned with MAFFT v.7.427 [@Katoh2013], followed by gene tree construction using IQTREE v.1.6.11 [@Nguyen2015]. The resulting gene trees were inspected in Geneious (https://www.geneious.com) in order to assess the presence of paralogs. On this basis, a total of 11 genes were deemed paralogous or potentially paralogous, and were removed from the dataset.

## Phylogenetic inference

Two sets of loci were selected for phylogenetic analysis. The first, referred to as the "full coverage" dataset, comprised genes having sequences for all 106 Cape _Ehrharta_ accessions,  _M. stipoides_ and _T. laevis_ and _O. sativa_. This dataset comprised a total of 235 genes. The second dataset, referred to as the "90% coverage" dataset, contained genes that were present in at least 90% of the samples, the cut off selected as a compromise between data missingness and the desire to use as many genes as possible. This dataset comprised a total of 307 genes. Both datasets yielded exons, introns, and supercontigs (comprising both exons and introns), giving six datasets in total. Individual genes were aligned using MAFFT with the settings --localpair --maxiterate 1000, the resulting alignments then being trimmed of gappy and poorly aligned regions with TrimAL v.1.2 using the -automated1 option [@Capella2009]. Alignment statistics were calculated using AMAS [@Borowiec2016].

The individual gene alignments were concatenated using AMAS (Borowiec, 2016), before being subjected to mixed-model, maximum likelihood (ML) phylogenetic analysis. For this purpose, the optimal model of sequence evolution for each locus was determined using IQTREE. Loci sharing a common model of sequence evolution were also identified and merged using IQTREE, which can implement Lanfear's Partitionfinder2 [@Chernomor2016, @Lanfear2012]. Due to the high computational burden of evaluating partitioning schemes, the relaxed hierarchical clustering algorithm (-rcluster) [Lanfear2014], which examines only the top n% partition merging schemes, was used. The exon supermatrices were partitioned using -rcluster 10, while the intron and supercontig supermatrices were run with -rcluster 2 due to computational time limits. The locus limits were used as the initial partitions. I then reconstructed ML trees on the merged-partition datasets using IQTREE. Node support was estimated using 1000 ultrafast bootstrap replicates (-bb 1000, UFBoot, Hoang 2017), with a bootstrap percentage (BS) ≥95 being interpreted as good support

Since the evolutionary histories of individual genes may differ from the history of the species tree owing to the effects of incomplete lineage sorting (ILS) and horizontal gene transfer, the datasets were also subjected to species tree inference using ASTRAL-III v5.6.3 [@Zhang2018], which employs a coalescent-based quartets approach to infer the species tree from the underlying gene trees. Individual gene trees were constructed from the loci alignments using IQTREE, with ASTRAL then being used to infer the species tree from the individual gene trees, with the local posterior probability (LPP) calculated as measure of support for each node. Since coalescent-based methods are less sensitive to missing taxa [@Hosner2016; @Sayyari2017; @Molloy2018], I used only the 90% coverage datasets for this analysis. All phylogenetic analyses were run on the University of Cape Town's High Performance Computing Facility.

## Genotyping-by-sequencing

To identify patterns of shared gene pools in the Setacea and Ramosa groups, genotyping-by-sequencing [GBS, @Elshire2011] was employed to sample the genome-wide SNP variation across these groups. Four DNA extracts per population were sent to Novogene Genome Sequencing Company Ltd. in Beijing, China for library preparation and sequencing following Novogene's protocols. In brief, each DNA sample was digested with restriction enzymes, and the resulting fragments were ligated to barcoded adaptors. The samples were then PCR amplified, pooled and size-selected. A Qubit® 2.0 fluorometer and an Agilent® 2100 bioanalyzer were used to check the concentration and insert sizes of the completed libraries. The samples were sequenced using paired-end sequencing on an Illumina platform sequencer, with a read length of 144 bp. The raw data were then filtered by Novogene to remove paired reads where either read  was adaptor contaminated, had ambiguous nucleotides accounting for > 10% of the read, or where  >50% of either read consisted of low quality nucleotides.

The dDocent pipeline [@Puritz2014] was used to map and call single nucleotide polymorphisms (SNPs). The pipeline was run separately on three well-supported clades resolved by the phylogenetic analyses, namely the Rehmannii, Ramosa and Setacea clades (Fig. \@ref(fig:MLtree), Fig. \@ref(fig:astraltree)). The reads were first trimmed using Trimmomatic to remove any reads with remaining adaptor contamination, bases having a quality score of <20, or having a 5 base window with an average quality score <10. The reads were then mapped to an _O. sativa_ genome (NCBI accessions AP008207 - AP008218) using the MEM algorithm of BWA with the default settings (-A 1 -B 4 -O 6). SNPs were called using using FreeBayes v.1.2.0 [@Garrison2012], which is a Bayesian-based variant detection program. The SNPs were concatenated into a variant call file (VCF) using VCFtools v.3.0 [@Danecek2011], and filtered using the dDocent pipeline recommendations with the following exceptions. Only variants that had been genotyped in ≥10% of individuals were retained, and individuals with >30% missing data were removed. Loci were also filtered out if they were missing >10% of individuals within five or more populations. A within-population Hardy-Weinberg Equilibrium filter was applied at a significance level of 0.001 to remove erroneous variant calls and reduce the dataset to only biallelic SNPs.

Individuals within each clade were then assigned to potential ancestral gene pools with a sparse non-negative matrix factorisation (sNMF) algorithm [@Frichot2014] using the R package _LEA_ [@Frichot2015]. The sNMF algorithm has a similar level of accuracy to likelihood-based inferences of population structure, such as STRUCTURE [@Pritchard2000] and ADMIXTURE [@Tang2005; @Alexander2009], but has a faster computing time [@Frichot2014]. One hundred ancestry coefficient matrices (Q matrices) were generated for each value of K between K = 1 and K = 20 for the Ramosa and Rehmannii clades, and between K = 1 and K = 25 for the Setacea clade. K represents the number of potential ancestral gene pools. The fit of each value of K given the data was evaluated using the average entropy criterion of 100 iterations. The entropy criterion evaluates the fit of the statistical model using a cross‐validation technique, with lower values representing a better fit [@Frichot2015]. However, I also used the value of K that corresponded to the number of putative species within each clade as suggested by the phylogenetic analyses. CLUMPAK (cluster Markov packager across K, @Kopelman2015) was used to summarise the Q matrices for the relevant K values, and the results visualised using the R package _pophelper_ [@Francis2015]. Finally, principal coordinate analyses (PCoA) of the filtered SNP dataset were generated with Euclidian distance matrices using the function "gl.pcoa" in the R package _dartR_ [@Gruber2018].



## Morphological measurements and analysis

Morphological traits of four flowering individuals per population in the Ramosa and Setacea groups were measured using a ruler, precise to 5 mm, digital vernier callipers, precise to 1 µm or a dissection microscope, precise to equipped with an eyepiece graticule, precise to 1 µm. In total, 24 floral and vegetative traits, comprising 17 measurements and seven potentially informative measurement ratios, were scored (Table 1). Of these traits, only 17 were used in downstream analyses to reduce autocorrelation. 

Analysis of the morphological data was informed by the phylogenetic and SNP-based results, as follows. First, the morphological data were analysed separately for three clades (the Ramosa, Rehmannii and Setacea clades) which were resolved, with good support, by the phylogenetic analysis. Second, although multivariate patterns of morphological trait variation were initially explored using principal components analysis, strong congruence between the clades resolved by the phylogenetic analyses and the population clusters revealed by analyses of the SNP data (i.e. sNMF and PCoA) allowed for the application of linear discriminant analysis (LDA) in order to assess morphological support for these groups. Linear discriminant analyses were conducted in R, using the package _MASS_ (@Venables2002). In addition to these multivariate analyses, variation in individual morphological traits was compared between putative species for the purpose of identifying diagnostic traits.

