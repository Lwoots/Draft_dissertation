# Methods section

## Field sampling



Field sampling of the mid- and high-elevation clades were conducted between November 2019 and January 2020. Sampling locations were chosen to cover as much of each taxon's range as possible, and encompassed much of the Western Cape, South Africa. The number of localities per taxon varied between 2 for the range restricted _E. setacea disticha_ and _E. setacea uniflora_, and 12 for the widespread _E. ramosa ramosa_. Between four and six individuals per population were collected from each locality, and were pressed to make voucher specimens. Young leaf and culm tissue from each voucher was silica-dried immediately  and stored in an airtight container at -20C to prevent DNA degradation. Additionally, collections made by GA Verboom of lowlands taxa during August 2018 were also used in this study. Most lowlands taxa were sampled in Namaqualand, and each taxon is represented by a single individual.  



## DNA extraction



DNA extraction of four individuals per population was undertaken at the systematics laboratory in HW Pearson, University of Cape Town. One hundred mg of frozen, silica-dried leaf and culm tissue was finely ground in liquid nitrogen using a mortar and pestle. Sterilised silica and a spatula tip of PVP was added to each sample before grinding, to increase friction and decrease extract polysaccharide content respectively. The DNA was extracted using a modified cetyl-trimethylammonium bromide (CTAB) method. CTAB solution and 2-Mercaptoethanol were added to the ground extracts. Next, 24:1 chloroform:isoamyl solution was added to remove solvents, and the DNA was precipitated using isopropanol at −20C. The precipitates were then washed three times with 70% ethanol. The resulting extracts were then RNAse treated, and purified using AMPure magnetic beads following the manufacturers instructions. The concentration and purity of each extract was checked using a NanoDrop ND-1000 spectrophotometer (ThermoFisher Scientific, Waltham, MA USA). Samples with concentrations ≥50 ng/μl and 260/280 absorbance ratios between 1.7 and 2 were used for genotyping-by-sequencing (GBS), while those with concentrations ≥25 ng/μl were used for targeted enrichment.

## Library preparation for targeted enrichment

Library preparation and hybridisation for targeted enrichment was carried out at the Sackler Phylogenomic Laboratory, within the Jodrell Laboratory at Royal Botanic Gardens, Kew (Richmond, Surrey, UK). The DNA concentration present in the extracts was measured with a QuantusTM fluorometer (Promega corporation, Madison USA) using the using QuantiFluorR dsDNA System kit (Promega corporation, Madison USA). The samples were diluted to 200 ng DNA in 26 $\mu$l with Milli-Q water. The DNA was then sheared to fragments an average of 350 bp long by sonicating them for 75s with a Covaris Focused-ultrasonicator M220 (Woburn Massachusetts 01801 www.covarisinc.com)

Library preparation was completed using NEBNxet Ultra II DNA Library Prep Kit for Illumina (New England Biolabs), using half the recommended volumes to maximise use of reagents and indexes. AMPure magnetic beads were used for size selection of DNA fragments. Libraries were indexed with the NEBNext Multiplex Oligos for Illumina (Dual Index Primer Set 1, New England Biolabs), and enriched with the following thermocycler conditions: Initial denaturation for 30s at 98$^\circ$C, 7 cycles of denaturation for 10s at 98$^\circ$C, annealing and extension for 75s at 65$^\circ$C, followed by a final extension for 5 mins at 65$^\circ$C. The resulting enriched libraries were cleaned with AMPure beads, and the quality of the libraries were checked using Agilent Technologies 4200 Tapestation (Agilent Technologies, Palo Alto, California, USA). A library was considered good quality if it had a concentration of greater than 4 ng.$\mu$l^-1^ and avg fragment size of 450 bp to 500 bp. If a library failed the quality check, it was either re-amplified, underwent size selection again, or was entirely repeated from the beginning of the process. 

 

## Hybridisation and targeted enrichment sequencing preparation


Libraries were normalised to a concentration of 10 nM and 10 $\mu$l per sample was pooled into batches of 12 or 24 samples per reaction. The pools were vacuum dried using a miVac Duo Concentrator (Genevac, UK) and subsequently eluted in 8 $\mu$l of 10 mM tris buffer. The pools were enriched using the Angiosperms-353 v 1 target capture kit (Johnson et al., 2018) following the manufacturers instructions (Arbor Biosciences, Ann Arbor, Michigan, USA). Hybridisation took place for 16h at 65$^\circ$C, and the resulting product was amplified with 12 cycles of PCR. The reaction quality was checked using a Agilent Technologies 4200 Tapestation (Agilent Technologies, Palo Alto, California, USA). Reactions were normalised to 4mM and pooled. Sequencing took place either at Macrogen (Seoul, South Korea) or on an Illumina® MiSeq at Royal Botanic Gardens, Kew (Richmond, Surrey, UK). Both produce 2 x 150 bp reads.

 

## Phylogenetic methods



**Read trimming and quality control**

The raw reads were cleaned using trimmomatic V0.39 (ref). First, Illuminaclip palindrome mode using the reference file TruSeq3-PE.fa removed Illumina sequencing adaptors. Palindrome mode had the following settings: SeedMismatches = 1, palindromeClipThreshold = 30, simpleClipThreshold = 6, minAdapterLength  =  2; keepBothReads = T RUE.  Second, poor quality reads were trimmed with the Maxinfo option. Maxinfo balances the utility of retaining reads of an informative length against the costs of incorrect bases. Initially, Maxinfo is lenient towards potential error calls at a shorter read length, and becomes more strict as read length increases. The settings used were targetLength = 40 and strictness = 85. Finally, reads shorter than 36 bases were removed using MinLength. Overall read quality and adaptor content of the remaining reads were checked using FastQC 0.11.8 (ref)



**Read assembly**

Reads were assembled using the pipeline HybPiper 1.3.1 (ref).  HybPiper consists of a series of python scripts that use SPAdes (ref) and other bioinfomatic tools to assemble reads to a target file. The pipeline first sorts and groups together individual reads for a gene by mapping each read to the gene sequence in the target file.  Once the reads are sorted by gene, they are de novo assembled using SPAdes, and then realigned to the reference sequence. If multiple contigs are assembled per gene, the contig with either the greatest depth or greatest similarity to the reference file is chosen for the consensus sequence. Hybpiper gives the option of two different mapping algorithms, BLASTX and bwa. I ran the pipeline using BLASTX, as it is a less strict algorithm than bwa, therefore maximising the number of reads mapped and the lengths of the final sequences. A coverage of four reads was considered sufficient to create a consensus sequence. Reads were mapped to a multi-species, amino acid target file matching the probes from the Angiosperm 353 baitset. In the case of a multi-species target file, such as the one used here, HybPiper can determine which target sequence for a gene is the most suitable given the sample.

The Hybpiper pipeline was also used to assemble the cleaned reads of a full genome of _Oryza sativa_ Japonica cultivar downloaded from Genbank (https://www.ncbi.nlm.nih.gov/sra/SRR10389404).



**Identification of paralogs, gene choice**

Paralogs are genes related by an ancestral duplication event, rather than by sharing a common origin as is the case with orthologous genes (Koonin 2005, Schrempf2020). A key assumption of phylogenetics is that the genes used within an analysis are orthologous. Fortunately, HypPiper is able to identify potential paralogs. If HybPiper 1.3.1 recovers two or more similar contigs that cover at least 85% of the coding region's reference sequence, it flags the region as containing potential paralogs. Note that two similar length contigs for a gene may also indicate the presence of an allele. The two can be differentiated by constructing a gene tree. A gene is paralogous if the main contigs cluster separately to the alternative contigs, as this indicates a gene duplication event. Alternatively, main and secondary contigs grouping as sisters within a gene would suggest alleles.

In this analysis, HybPiper flagged 50 genes with paralog warnings. Within each gene, the number of samples flagged with paralogs varied between 1 and 39 samples. I disregarded genes with less than 2 flagged samples, as these were more likely to be alleles rather than paralogs. This left 18 genes that contained potential paralogs. HybPiper contains a script, paralog_retriever.py that will extract both the main and secondary contigs for a gene into a fasta file. Each resulting fasta was then aligned with MAFFT, followed by genetree construction using IQtree 1.6.11.  The trees were inspected in Geneious. While it wasn't always clear cut whether the tree exhibited paralogs or not, I errored on the side of caution and removed any gene that wasn't obviously allelic. Therefore a total of 11 genes were deemed paralogs, and were removed from the dataset.

Two sets of loci were chosen for further phylogenetic analysis. One, refered to as the full coverage dataset (FCD), retained genes that were present in all 109 samples, outgroups and rice included. This was a total of 235 genes (Table). The other, referred to as the ninety percent coverage dataset (NCD), retained genes that were present in at least 90% of all samples. This cut off was chosen as a compromise between missing data, and using as many genes as possible. These dataset divisions were used for exons, supercontigs, and introns, giving six datasets in total. Individual genes were aligned using MAFFT 7.427 with the settings --localpair --maxiterate 1000. The resulting alignments were then trimmed of gappy and poorly aligned regions with TrimAL 1.2. 



**Maximum likelihood trees** 

The alignments were concatenated using AMAS (ref), which also generates a partition file delimiting where each loci starts in the concatenated alignment. Most loci have a unique evolutionary history, and are able to evolve independently of the rest of the genome. Each region is therefore expected to have a different rate and pattern of evolution. Therefore each locus should be fitted with a model of evolution that best fits its history. To reduce parameter space, it is also best to partition together loci with similar models of evolution. IQtree is able to fit 200 odd models of evolution to the genes and can implement Lanfear's partitionfinder2 (Chernomor 2016, Lanfear). Due to the high computational burden, I choose to use the relaxed hierarchical clustering algorithm (-rcluster) (Lanfear2014), which only examines the top n% partition merging schemes. The exon supermatrices were partitioned using -rcluster 10, while the intron and supercontig supermatrices were run with -rcluster 2 due to computational time limits. The locus limits were used as the initial partitions.

I then reconstructed ML trees on the merged partition datasets using IQtree v. For support values, I used 1000 ultrafast bootstraps (UFBoot, Hoang 2017), and Shimodaira-Hasegawa approximate likelihood-ratio test (SH-aLRT) (Shimodaira 1999, Guindon 2010) implemented with -alrt 1000. SH-aLRT calculates if there is a significant difference between the likelihoods of the best and the second best topological arrangements around a given branch (Anisimova 2006, Guindon 2010). With these support metrics, a node is considered to have good support if it has greater than 95% UFBoot value, and greater than 80% Sh-aLRT value.



**Multi-species coalescent trees**

The evolutionary history of a gene often differs from the history of a species due to incomplete lineage sorting, horizontal gene transfer and hybridisation resulting in gene trees that differ from the true species tree. Concatenated ML methods are unlikely to capture these patterns. Conversely, the multi-species coalescent model allows the history genes to be modeled separately from the species history, therefore allowing for processes such as ILS to occur. Summary-based methods of species tree estimation such as ASTRAL are consistent with multi-species coalescent theory, and are therefore thought to be more accurate than ML for large datasets. Astral estimates the species tree that has the most quartets that are shared with the gene trees. Individual gene trees were constructed from the loci alignments using IQTree with the default settings. ASTRAL-III v5.6.3 was used to infer the species tree from the individual gene trees. As coalescent-based methods are less sensitive to missing taxa (Hosner 2016, Sayyari 2017, Molloy2018), I used only the ninety-percent coverage datasets for this analysis.



## GBS 



How we chose which populations to sequence

Four DNA extracts per population were sent to Novogene Genome Sequencing Company Ltd. in Beijing, China for library preparation and sequencing following Novogene's protocols. In brief, each DNA sample was digested with restriction enzymes, and the resulting fragments were ligated to barcoded adaptors. The samples are then PCR amplified, pooled and size-selected. A Qubit® 2.0 fluorometer and a Agilent® 2100 bioanalyzer were used to check the concentration and insert sizes of the completed libraries. The samples were sequenced using paired-end sequencing on a Illumina platform, with a read length of 144 bp. The raw data was then filtered by Novogene to remove paired reads where either read is adaptor contaminated, has ambiguous nucleotides accounting for > 10 % of the read, or where more than 50% of either read consists of poor quality nucleotides.

The dDocent pipeline (ref) was used to map and call SNPs. The pipeline was run separately on each of the Rehmannii, Ramosa and Rupestris clades. First, the reads were trimmed using Trimmomatic to remove any remaining reads with adaptor contamination, or with bases below a quality score of 20, or that contain a five base pair window with an average quality score of less than ten. The reads were then mapped to a reference genome (link to ncbi) using the MEM algorithm of BWA with the default settings (-A 1 -B 4 -O 6). Single nucleotide polymorphisms (SNPs) were called using using FreeBayes v1.2.0 (Garrison & Marth, 2012), which is a Bayesian-based variant detection program. The SNPs were concatenated into a variant call file (VCF) using VCFtools v3.0 (Danecek et al., 2011), and filtered using the dDocent pipeline recommendations with the following exceptions. I kept only variants that had been genotyped in at least 10% of individuals, and individuals with more than 30% missing data were removed. Loci were also filtered if they were missing in over 10% of individuals within five or more populations. A within-population Hardy-Weinberg Equilibrium filter was applied at a significance level of 0.001 to remove erroneous variant calls and reduce the dataset to only biallelic SNPs.

Individuals within each clade were then assigned to potential ancestral gene pools with a sparse non-negative matrix factorisation (sNMF) algorithm (@Frichot2014) using the R package _LEA_ (ref). The sNMF algorithm has a similar level of accuracy to likelihood-based inferences of population structure, such as STRUCTURE (ref) and ADMIXTURE (ref), but with a faster computing time (@Frichot2014). One hundred ancestry coefficient matrices (Q matrices) were generated for each value of K between K = 1 and K = 20 for the Ramosa and Rehmannii clades, and  K = 1 and K = 25 for the Rupestris clade. K represents the number of potential ancestral gene pools. The quality of the fit of each value of K given the data was evaluated using the average entropy criterion of the one hundred runs. The entropy criterion evaluates the fit of the statistical model using a cross‐validation technique, with lower values representing a better fit (@Frichot2015). However, I also used the value of K that corresponded to the number of putative species within each clade that was recovered by the phylogenetic analyses. Clumpak (cluster Markov packager across K, Kopelman et al., 2015) was used to summarise the Q matrices for the relevant K values, and the results visualised using the R package pophelper. Finally, PCOAs of the filter SNP dataset were generated using the packages dartR and adegenet.



## Morphological measurements and analysis



Morphological traits of four flowering individuals per population in the high elevation clades were measured using either digital vernier callipers or a dissection microscope. If a given population had fewer than four flowering individuals. Only one individual per taxon for the low-elevation clades was phenotyped. Where possible, individuals were corresponding to the phylogeny tips were selected, although occasionally another individual from the same population had to be used if the original sequenced individual was not in flower.  For _E. microlaena_ a herbarium specimen (Verboom 695) from the same locality as our collection was used, as all our voucher specimens were under-developed. In total, 18 floral and vegetative traits were measured, as shown in Table. Potentially informative ratios of these traits, for example spikelet shape (spikelet width x spikelet length), were also used in downstream analyses (Table).



Results from the phylogenetic and GBS analyses were used to inform the structure of the morphological analysis. Each major high-elevation clade was analysed separately in order to examine fine-scale variation, and individuals were grouped according to potential new taxa, rather than existing taxonomy. A principal components analysis was used to visualise morphological similarities between taxa. Linear discriminant analyses to maximise the distance between groups. I also present univariate boxplots of particularly informative traits.

